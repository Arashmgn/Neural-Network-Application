{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e073d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "98bdd21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs  = np.random.randn(4,1)\n",
    "weights = np.random.randn(10,4)\n",
    "biases  = np.random.randn(10,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "7f48d885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=weights.dot(inputs)+biases\n",
    "\n",
    "x=x>0\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86d6fa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 0, 0, 2, 0, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dot([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "c8b03ba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self,features,neurons,activationfunc):\n",
    "        self.col                 = features\n",
    "        self.weight              = np.random.randn(neurons,self.col)\n",
    "        self.bias                = np.random.randn(neurons,1)\n",
    "        self.input               = []\n",
    "        self.output              = []\n",
    "        self.output_activate     = []\n",
    "        self.activationfunc      = activationfunc\n",
    "        \n",
    "    def feedforward(self,inputs):\n",
    "        self.output              = self.weight.dot(inputs.transpose())+self.bias\n",
    "        self.output_activate     = self.activationFunction(self.output)  \n",
    "        return self.output_activate \n",
    "    \n",
    "    def activationReLu(self,inputs):\n",
    "        return np.maximum(inputs,0)\n",
    "        \n",
    "    def derivativeReLu(self,inputs):\n",
    "        return inputs > 0\n",
    "    \n",
    "    def activationSoftMax(self,inputs):\n",
    "        return np.exp(inputs)/np.sum(np.exp(inputs))\n",
    "        \n",
    "    def derivativeSofMax(self,inputs):\n",
    "        return inputs*(1-inputs)\n",
    "    \n",
    "    def activationFunction(self,inputs):\n",
    "        if self.activationfunc   == \"relu\":\n",
    "            return self.activationReLu(inputs)\n",
    "        elif self.activationfunc == \"softmax\":\n",
    "            return self.activationSoftMax(inputs)\n",
    "        else:\n",
    "            return inputs\n",
    "        \n",
    "    \n",
    "    def derivativeFunction(self):\n",
    "        if self.activationfunc   == \"relu\":\n",
    "            return self.derivativeReLu(self.output)\n",
    "        elif self.activationfunc == \"softmax\":\n",
    "            return self.derivativeSofMax(self.output_activate)\n",
    "        else :\n",
    "            return inputs\n",
    "        \n",
    "    def backpropagation(self,inputs):\n",
    "        #derivative of loss for biases\n",
    "        dEdB=inputs*self.derivativeFunction()\n",
    "        \n",
    "        #derivative of loss for weights\n",
    "        dEdW=inputs*self.derivativeFunction()*self.input\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "350ff523",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer  = Layer(4,10,\"relu\")\n",
    "layer2 = Layer(10,10,\"softmax\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "97119209",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (10,1) and (10,1) not aligned: 1 (dim 1) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-660-535a501140eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mout2\u001b[0m  \u001b[1;33m=\u001b[0m  \u001b[0mlayer2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlayer2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackpropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-657-e0addd769092>\u001b[0m in \u001b[0;36mbackpropagation\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackpropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m#derivative of loss for biases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mdEdB\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mderivativeFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (10,1) and (10,1) not aligned: 1 (dim 1) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "out1  =  layer.feedforward(inputs.transpose())\n",
    "\n",
    "out2  =  layer2.feedforward(out1.transpose())\n",
    "\n",
    "layer2.backpropagation(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "10453ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 10, 18])"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d6741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
